{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Yolo-web.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "fFaMWuFPBGqB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a2543ab-c1b9-408b-d583-b5e19e5406ac"
      },
      "source": [
        "import torch\n",
        "print('PyTorch %s %s' % (torch.__version__, torch.cuda.get_device_properties(0) if torch.cuda.is_available() else 'CPU'))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "PyTorch 1.9.0+cu102 _CudaDeviceProperties(name='Tesla T4', major=7, minor=5, total_memory=15109MB, multi_processor_count=40)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yzM0SdckCm4T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44acaae8-0c3a-4293-b9ef-b0528cdc29ff"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "%cd /content/\n",
        "\n",
        "# import yolo project\n",
        "!rm -rf yolov5\n",
        "!git clone https://github.com/ultralytics/yolov5/\n",
        "\n",
        "# import training data project\n",
        "!rm -rf yolo-training-data\n",
        "!git clone https://github.com/bhecquet/yolo-training-data\n",
        "\n",
        "%cd yolov5"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content\n",
            "Cloning into 'yolov5'...\n",
            "remote: Enumerating objects: 8571, done.\u001b[K\n",
            "remote: Counting objects: 100% (285/285), done.\u001b[K\n",
            "remote: Compressing objects: 100% (175/175), done.\u001b[K\n",
            "remote: Total 8571 (delta 163), reused 191 (delta 110), pack-reused 8286\u001b[K\n",
            "Receiving objects: 100% (8571/8571), 9.57 MiB | 3.94 MiB/s, done.\n",
            "Resolving deltas: 100% (5905/5905), done.\n",
            "Cloning into 'yolo-training-data'...\n",
            "remote: Enumerating objects: 9026, done.\u001b[K\n",
            "remote: Counting objects: 100% (9026/9026), done.\u001b[K\n",
            "remote: Compressing objects: 100% (7355/7355), done.\u001b[K\n",
            "remote: Total 9026 (delta 1687), reused 8963 (delta 1638), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (9026/9026), 50.07 MiB | 14.10 MiB/s, done.\n",
            "Resolving deltas: 100% (1687/1687), done.\n",
            "/content/yolov5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bub53qzuoIcv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5cce7900-afce-4b03-de91-f58788f5ab21"
      },
      "source": [
        "# crÃ©ation des donnÃ©es de test / entrainement\n",
        "!python /content/yolo-training-data/generate_train_files.py /content/yolo-training-data/field-detector/dataset_extracted /content/yolo-training-data/field-detector/dataset_generated_small --output /content/yolov5/dataset"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:root:2721 files added to /content/yolov5/dataset/training\n",
            "INFO:root:290 files added to /content/yolov5/dataset/testing\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DBZWhwvlBUvF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "676cbb43-4444-4a11-d91c-f5e5b2a07ef4"
      },
      "source": [
        "import torch\n",
        "import os\n",
        "from IPython.display import Image, clear_output \n",
        "print('PyTorch %s %s' % (torch.__version__, torch.cuda.get_device_properties(0) if torch.cuda.is_available() else 'CPU'))\n",
        "best_fitness = 0.0\n",
        "cfg = '/content/yolo-training-data/field-detector/data/web-generated.yaml'\n",
        "#cfg = 'web-generated.yaml'\n",
        "model = 'yolov5m.pt'\n",
        "\n",
        "epoch_to_run = 2\n",
        "\n",
        "name = os.path.basename(cfg).split(\".\")[0] + '-' + model.split('.')[0]\n",
        "\n",
        "\n",
        "!python train.py --img 448 --batch 16 --epochs $epoch_to_run --data $cfg --weights $model --name $name --exist-ok \n",
        "weights_file_path = '/content/yolov5/runs/train/%s/weights/best.pt' % (name)\n",
        "weights_file_path_google_drive = '/content/drive/My\\ Drive/best_%s_%d.pt' % (name, epoch_to_run)\n",
        "w = torch.load(weights_file_path)\n",
        "\n",
        "fitness = w['best_fitness']\n",
        "print(\"epoch completed: \" + str(epoch_to_run))\n",
        "print(\"mAp: \" + str(fitness))\n",
        "\n",
        "\n",
        "!cp $weights_file_path $weights_file_path_google_drive\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "PyTorch 1.9.0+cu102 _CudaDeviceProperties(name='Tesla T4', major=7, minor=5, total_memory=15109MB, multi_processor_count=40)\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5m.pt, cfg=, data=/content/yolo-training-data/field-detector/data/web-generated.yaml, hyp=data/hyps/hyp.scratch.yaml, epochs=2, batch_size=16, imgsz=448, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, evolve=None, bucket=, cache_images=False, image_weights=False, device=, multi_scale=False, single_cls=False, adam=False, sync_bn=False, workers=8, project=runs/train, entity=None, name=web-generated-yolov5m, exist_ok=True, quad=False, linear_lr=False, label_smoothing=0.0, upload_dataset=False, bbox_interval=-1, save_period=-1, artifact_alias=latest, local_rank=-1\n",
            "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5/ âœ…\n",
            "YOLOv5 ðŸš€ v5.0-327-gb60b62e torch 1.9.0+cu102 CUDA:0 (Tesla T4, 15109.75MB)\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.2, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
            "\u001b[34m\u001b[1mWeights & Biases: \u001b[0mrun 'pip install wandb' to automatically track and visualize YOLOv5 ðŸš€ runs (RECOMMENDED)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
            "2021-07-29 14:05:40.318308: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "Overriding model.yaml nc=80 with nc=9\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      5280  models.common.Focus                     [3, 48, 3]                    \n",
            "  1                -1  1     41664  models.common.Conv                      [48, 96, 3, 2]                \n",
            "  2                -1  1     65280  models.common.C3                        [96, 96, 2]                   \n",
            "  3                -1  1    166272  models.common.Conv                      [96, 192, 3, 2]               \n",
            "  4                -1  1    629760  models.common.C3                        [192, 192, 6]                 \n",
            "  5                -1  1    664320  models.common.Conv                      [192, 384, 3, 2]              \n",
            "  6                -1  1   2512896  models.common.C3                        [384, 384, 6]                 \n",
            "  7                -1  1   2655744  models.common.Conv                      [384, 768, 3, 2]              \n",
            "  8                -1  1   1476864  models.common.SPP                       [768, 768, [5, 9, 13]]        \n",
            "  9                -1  1   4134912  models.common.C3                        [768, 768, 2, False]          \n",
            " 10                -1  1    295680  models.common.Conv                      [768, 384, 1, 1]              \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  1   1182720  models.common.C3                        [768, 384, 2, False]          \n",
            " 14                -1  1     74112  models.common.Conv                      [384, 192, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  1    296448  models.common.C3                        [384, 192, 2, False]          \n",
            " 18                -1  1    332160  models.common.Conv                      [192, 192, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  1   1035264  models.common.C3                        [384, 384, 2, False]          \n",
            " 21                -1  1   1327872  models.common.Conv                      [384, 384, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  1   4134912  models.common.C3                        [768, 768, 2, False]          \n",
            " 24      [17, 20, 23]  1     56574  models.yolo.Detect                      [9, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [192, 384, 768]]\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
            "Model Summary: 391 layers, 21088734 parameters, 21088734 gradients\n",
            "\n",
            "Transferred 500/506 items from yolov5m.pt\n",
            "Scaled weight_decay = 0.0005\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD with parameter groups 83 weight, 86 weight (no decay), 86 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mversion 1.0.3 required by YOLOv5, but version 0.1.12 is currently installed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'dataset/training/labels.cache' images and labels... 2721 found, 0 missing, 33 empty, 0 corrupted: 100% 2721/2721 [00:00<00:00, 26790378.37it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning 'dataset/testing/labels.cache' images and labels... 290 found, 0 missing, 4 empty, 0 corrupted: 100% 290/290 [00:00<00:00, 1668515.99it/s]\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "Plotting labels... \n",
            "\n",
            "\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 3.08, Best Possible Recall (BPR) = 0.9797. Attempting to improve anchors, please wait...\n",
            "\u001b[34m\u001b[1mautoanchor: \u001b[0mRunning kmeans for 9 anchors on 34408 points...\n",
            "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.25: 1.0000 best possible recall, 5.51 anchors past thr\n",
            "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=9, img_size=448, metric_all=0.374/0.794-mean/best, past_thr=0.530-mean: 21,14,  22,20,  73,19,  103,27,  122,39,  232,26,  244,42,  373,34,  316,84\n",
            "\u001b[34m\u001b[1mautoanchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.8299: 100% 1000/1000 [00:08<00:00, 117.17it/s]\n",
            "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.25: 1.0000 best possible recall, 5.44 anchors past thr\n",
            "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=9, img_size=448, metric_all=0.377/0.830-mean/best, past_thr=0.541-mean: 15,15,  21,21,  58,20,  97,24,  119,41,  207,29,  334,27,  311,39,  241,68\n",
            "\u001b[34m\u001b[1mautoanchor: \u001b[0mNew anchors saved to model. Update model *.yaml to use these anchors in the future.\n",
            "\n",
            "Image sizes 448 train, 448 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to runs/train/web-generated-yolov5m\n",
            "Starting training for 2 epochs...\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "       0/1     3.24G   0.09742   0.09828   0.05801        53       448: 100% 171/171 [00:53<00:00,  3.22it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 10/10 [00:05<00:00,  1.89it/s]\n",
            "                 all        290       3893      0.232      0.472      0.255     0.0795\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "       1/1     4.69G    0.0638   0.08558   0.04528        30       448: 100% 171/171 [00:48<00:00,  3.54it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 10/10 [00:06<00:00,  1.47it/s]\n",
            "                 all        290       3893      0.487      0.625      0.571        0.2\n",
            "               field        290        706      0.496      0.807      0.742      0.259\n",
            "               radio        290        440      0.573      0.914      0.806       0.38\n",
            "              button        290        278      0.507      0.457       0.53      0.155\n",
            "    radio_with_label        290        444      0.484      0.448      0.427      0.129\n",
            "    field_with_label        290        601        0.5      0.572       0.55      0.144\n",
            "          field_line        290        283      0.529      0.513      0.509      0.132\n",
            "            checkbox        290        437      0.477       0.87      0.702      0.322\n",
            " checkbox_with_label        290        434      0.365      0.313      0.293     0.0792\n",
            "field_line_with_label        290        270      0.454       0.73      0.581      0.204\n",
            "2 epochs completed in 0.033 hours.\n",
            "\n",
            "Optimizer stripped from runs/train/web-generated-yolov5m/weights/last.pt, 42.5MB\n",
            "Optimizer stripped from runs/train/web-generated-yolov5m/weights/best.pt, 42.5MB\n",
            "epoch completed: 2\n",
            "mAp: [    0.23743]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4w0zxEoVfGVj"
      },
      "source": [
        "from utils import utils; utils.plot_results()\n",
        "\n",
        "w = torch.load('weights/best.pt')\n",
        "epochs_completed = str(w['epoch'])\n",
        "fitness = w['best_fitness']\n",
        "print(\"epoch completed: \" + epochs_completed)\n",
        "print(\"mAp: \" + str(fitness))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z-kDXOW3bQVL",
        "outputId": "ddeb899e-1a0e-487f-82fd-2134259e1437"
      },
      "source": [
        "!python3 detect.py  --source \"dataset_real/ac3bfc152e8ba5ba0b3423755fe6d234.jpg\" --weights /content/drive/My\\ Drive/best_web-generated_-1.pt --img-size 640 --exist-ok  --save-txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Namespace(agnostic_nms=False, augment=False, classes=None, conf_thres=0.25, device='', exist_ok=True, img_size=640, iou_thres=0.45, name='exp', nosave=False, project='runs/detect', save_conf=False, save_txt=True, source='dataset_real/ac3bfc152e8ba5ba0b3423755fe6d234.jpg', update=False, view_img=False, weights=['/content/drive/My Drive/best_web-generated_-1.pt'])\n",
            "YOLOv3 ðŸš€ bh1-8-g0ae89779 torch 1.8.1+cu101 CUDA:0 (Tesla P100-PCIE-16GB, 16280.875MB)\n",
            "\n",
            "Fusing layers... \n",
            "Model Summary: 269 layers, 62589598 parameters, 0 gradients, 155.9 GFLOPS\n",
            "image 1/1 /content/yolov3/dataset_real/ac3bfc152e8ba5ba0b3423755fe6d234.jpg: 384x640 8 fields, 2 radios, 3 buttons, 2 radio_with_labels, Done. (0.026s)\n",
            "Results saved to runs/detect/exp\n",
            "10 labels saved to runs/detect/exp/labels\n",
            "Done. (0.066s)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}